{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99397192-ddf8-4862-89b8-70fbe8f89f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a simple custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'data': self.data[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b427a2a-89ec-4d0f-bbc4-aa43bbff86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset, prop = 0.9):\n",
    "    authors = list(set(dataset.labels))\n",
    "    random.shuffle(authors)\n",
    "\n",
    "    train_len = math.floor(len(authors) * prop)\n",
    "    train_authors = authors[:train_len]\n",
    "    val_authors = authors[train_len:]\n",
    "\n",
    "    print(f'{len(train_authors)} authors for training - {len(val_authors)} authors for validation')\n",
    "\n",
    "    train_idxs = []\n",
    "    val_idxs = []\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc='Splitting dataset'):\n",
    "        w = dataset.get_label(i)[1]\n",
    "        if w in train_authors:\n",
    "            train_idxs.append(i)\n",
    "        if w in val_authors:\n",
    "            val_idxs.append(i)\n",
    "\n",
    "    train = torch.utils.data.Subset(dataset, train_idxs)\n",
    "    val = torch.utils.data.Subset(dataset, val_idxs)\n",
    "\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dbee968-341c-42b8-a7d4-a47e7ec97175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random data\n",
    "data = np.random.randn(100, 3)  # 100 samples, each with 3 features\n",
    "labels = np.random.randint(0, 2, 100)  # Binary labels for each sample\n",
    "\n",
    "breakpoint()\n",
    "\n",
    "# Create an instance of MyDataset\n",
    "dataset = MyDataset(data, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48abba1a-75df-45d7-8539-bf81c1849e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8aa100-9e02-41f2-b9ef-25a02c581d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 authors for training - 1 authors for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting dataset:   0%|                                                                                                                                                            | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MyDataset' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds, val_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_val_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m, in \u001b[0;36mtrain_val_split\u001b[0;34m(dataset, prop)\u001b[0m\n\u001b[1;32m     12\u001b[0m val_idxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplitting dataset\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label\u001b[49m(i)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m train_authors:\n\u001b[1;32m     17\u001b[0m         train_idxs\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyDataset' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = train_val_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b6524-21cc-4bb2-a23c-7481c355afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "batch_size = 10\n",
    "breakpoint()\n",
    "dataloader = DataLoader(train_ds, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(\"Data:\", batch['data'])\n",
    "    print(\"Labels:\", batch['label'])\n",
    "    print()  # Blank line for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01716dfa-f937-4c1b-bcd8-11a924878ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce1b40e-9459-43c6-9a17-c04b1a1c91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from Smooth_AP_loss import SmoothAP\n",
    "from Smooth_AP_loss_o import SmoothAP as SmoothAP1\n",
    "from Smooth_AP_loss2 import SmoothAP as SmoothAP2\n",
    "from Smooth_AP_loss3 import SoftAPLoss as SmoothAP3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a5844a2-f45a-4bda-8ff0-83854f451b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)  # For reproducibility\n",
    "batch_size = 16*4\n",
    "num_classes = 4\n",
    "feat_dims = 5\n",
    "anneal = 0.01\n",
    "labels = torch.tensor([i // int(batch_size/num_classes) for i in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3c7ddb4-f41c-4b58-9a10-be9e12a4b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(batch_size, feat_dims, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485b8ef4-f3e2-45a2-8ccc-6a60923a1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmoothAP(anneal=anneal, batch_size=batch_size, num_id=num_classes, feat_dims=feat_dims)\n",
    "SmoothAP1(anneal=anneal, batch_size=batch_size, num_id=num_classes, feat_dims=feat_dims)\n",
    "SmoothAP2(anneal=anneal, batch_size=batch_size, num_id=num_classes, feat_dims=feat_dims)\n",
    "smooth_ap_loss3 = SmoothAP3(anneal=anneal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4622aa4a-a601-4fb4-9f33-377cc0a1522f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6556], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_initial = smooth_ap_loss(inputs)\n",
    "loss_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86400007-3711-4ce9-8203-8f81f684d235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6556], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_initial1 = smooth_ap_loss1(inputs)\n",
    "loss_initial1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99133bf-a19f-44a4-b537-5fa71ff8597a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6556], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_initial2 = smooth_ap_loss2(inputs)\n",
    "loss_initial2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e62a556-cd58-483d-8048-4193c618c8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7053, grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_initial3 = smooth_ap_loss3(inputs, labels)\n",
    "loss_initial3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ebfdfa1-17ff-44dd-aa8c-78db8c2d7cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([i // int(batch_size/num_classes) for i in range(batch_size)])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d58980b-129a-45b2-abb6-962c621b10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_and_memory(loss_fn, embeddings):\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_time = time.time()\n",
    "    loss = loss_fn(embeddings)\n",
    "    loss.backward()\n",
    "    end_time = time.time()\n",
    "    memory_allocated = torch.cuda.max_memory_allocated() / 1024**2  # Convert to MB\n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time, memory_allocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d8021c4-be9e-494b-9131-377cb6d25bce",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument to reset_peak_memory_stats",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m         SmoothAP(anneal\u001b[38;5;241m=\u001b[39manneal, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_id\u001b[38;5;241m=\u001b[39mnum_classes, feat_dims\u001b[38;5;241m=\u001b[39mfeat_dims),\n\u001b[1;32m      3\u001b[0m         SmoothAP1(anneal\u001b[38;5;241m=\u001b[39manneal, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_id\u001b[38;5;241m=\u001b[39mnum_classes, feat_dims\u001b[38;5;241m=\u001b[39mfeat_dims),\n\u001b[1;32m      4\u001b[0m         SmoothAP2(anneal\u001b[38;5;241m=\u001b[39manneal, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_id\u001b[38;5;241m=\u001b[39mnum_classes, feat_dims\u001b[38;5;241m=\u001b[39mfeat_dims)\n\u001b[1;32m      5\u001b[0m     ]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, loss_fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loss_fns, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     elapsed_time, memory_allocated \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_time_and_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmoothAPLoss\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Time = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, Memory = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmemory_allocated\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mMB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m, in \u001b[0;36mmeasure_time_and_memory\u001b[0;34m(loss_fn, embeddings)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_time_and_memory\u001b[39m(loss_fn, embeddings):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_peak_memory_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(embeddings)\n",
      "File \u001b[0;32m/cluster/qy41tewa/rl-map/rlmap/icadr23/venv/lib/python3.8/site-packages/torch/cuda/memory.py:309\u001b[0m, in \u001b[0;36mreset_peak_memory_stats\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reset the \"peak\" stats tracked by the CUDA memory allocator.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03mSee :func:`~torch.cuda.memory_stats` for details. Peak stats correspond to the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    management.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_resetPeakMemoryStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument to reset_peak_memory_stats"
     ]
    }
   ],
   "source": [
    "loss_fns = [\n",
    "        SmoothAP(anneal=anneal, batch_size=batch_size, num_id=num_classes, feat_dims=feat_dims),\n",
    "        SmoothAP1(anneal=anneal, batch_size=batch_size, num_id=num_classes, feat_dims=feat_dims),\n",
    "        SmoothAP2(anneal=anneal, batch_size=batch_size, num_id=num_classes, feat_dims=feat_dims)\n",
    "    ]\n",
    "\n",
    "for i, loss_fn in enumerate(loss_fns, start=1):\n",
    "    elapsed_time, memory_allocated = measure_time_and_memory(loss_fn, inputs)\n",
    "    print(f\"SmoothAPLoss{i}: Time = {elapsed_time:.4f}s, Memory = {memory_allocated:.2f}MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72003e41-6fc1-4afb-bb57-93112f061891",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a70722a2-89c3-4717-a381-28e41dc9f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(batch_size, feat_dims, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13b173eb-c1d8-4224-9390-c5eb83c7df53",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.Size' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
     ]
    }
   ],
   "source": [
    "inputs.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94382945-f705-46c2-9d9f-546c202fea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19b32698-28c3-4057-b3a9-ab6832d809fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)  # For reproducibility\n",
    "batch_size = 4*4\n",
    "num_classes = 4\n",
    "feat_dims = 5\n",
    "anneal = 0.01\n",
    "labels = torch.tensor([i // int(batch_size/num_classes) for i in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45026d5e-1777-472c-89ab-86cd8b278d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(batch_size, feat_dims, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09848055-06a5-46b9-9acf-561673056e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784],\n",
       "        [-1.2345, -0.0431, -1.6047, -0.7521,  1.6487],\n",
       "        [-0.3925, -1.4036, -0.7279, -0.5594, -0.7688],\n",
       "        [ 0.7624,  1.6423, -0.1596, -0.4974,  0.4396],\n",
       "        [-0.7581,  1.0783,  0.8008,  1.6806,  1.2791],\n",
       "        [ 1.2964,  0.6105,  1.3347, -0.2316,  0.0418],\n",
       "        [-0.2516,  0.8599, -1.3847, -0.8712, -0.2234],\n",
       "        [ 1.7174,  0.3189, -0.4245,  0.3057, -0.7746],\n",
       "        [-1.5576,  0.9956, -0.8798, -0.6011, -1.2742],\n",
       "        [ 2.1228, -1.2347, -0.4879, -0.9138, -0.6581],\n",
       "        [ 0.0780,  0.5258, -0.4880,  1.1914, -0.8140],\n",
       "        [-0.7360, -1.4032,  0.0360, -0.0635,  0.6756],\n",
       "        [-0.0978,  1.8446, -1.1845,  1.3835,  1.4451],\n",
       "        [ 0.8564,  2.2181,  0.5232,  0.3466, -0.1973],\n",
       "        [-1.0546,  1.2780, -0.1722,  0.5238,  0.0566],\n",
       "        [ 0.4263,  0.5750, -0.6417, -2.2064, -0.7508]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9332299e-de8e-4ffe-93c1-3b2d07dda8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = torch.matmul(inputs, inputs.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f28c8664-9e23-43c7-a7ab-756ff09582d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab08d7aa-5513-4fa5-9d93-c20d30cdd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = torch.mm(inputs, inputs.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15863c09-c168-4b24-ba3f-066758978f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44d533ca-532e-4636-abc4-7f59640f5495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(distance,dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "446370a3-52d2-47e6-a989-24f59e1ee418",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.randint(1,3,(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e20740f7-8fee-4feb-95c6-5a150f67d483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 2],\n",
       "        [1, 1, 2, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 2, 2, 2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52fee876-1c57-4f16-9350-d327d1163e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1, -1,  0],\n",
       "        [ 0,  0,  0, -1],\n",
       "        [ 1,  1,  0,  0],\n",
       "        [ 1,  1,  0,  0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n - n[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4826c67-175e-4fc3-802f-8b661065be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n - n[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e83b5-98cd-4c7d-8f5f-2d8e093a911b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icadr",
   "language": "python",
   "name": "icadr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
